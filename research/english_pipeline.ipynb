{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b43a8d",
   "metadata": {},
   "source": [
    "Fetching and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fa8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Prepared 5 comments.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, requests, pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from dataPipeline.services.nlp_engine import NLPEngine\n",
    "\n",
    "# We fetch from the dedicated English endpoint\n",
    "API_URL = \"http://localhost:8000/api/retrieve/cmtsep/en\"\n",
    "response = requests.get(API_URL)\n",
    "df = pd.DataFrame(response.json())\n",
    "\n",
    "if df.empty:\n",
    "    print(\"[!] No English comments found.\")\n",
    "else:\n",
    "    # Double-check filter: ensure we only have 'en' and unprocessed rows\n",
    "    unprocessed = df[\n",
    "        (df['language'] == 'en') & \n",
    "        (df['cleaned_text'].isna() | (df['cleaned_text'] == \"\"))\n",
    "    ].copy()\n",
    "\n",
    "    if not unprocessed.empty:\n",
    "        # 1. Cleaning\n",
    "        unprocessed['token_list'] = NLPEngine.clean_comments(unprocessed['comment'])\n",
    "        unprocessed['cleaned_text'] = unprocessed['token_list'].apply(lambda x: \" \".join(x))\n",
    "        \n",
    "        # 2. Sentiment (New Step)\n",
    "        unprocessed['sentiment'] = NLPEngine.analyze_sentiment_lstm(unprocessed['cleaned_text'])\n",
    "        \n",
    "        unprocessed = unprocessed[unprocessed['cleaned_text'] != \"\"].copy()\n",
    "        print(f\"[*] Prepared {len(unprocessed)} English comments for Topic Modeling.\")\n",
    "    else:\n",
    "        print(\"[!] All English comments already processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29b0ed",
   "metadata": {},
   "source": [
    "Topic Modeling Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd744c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores: {'LDA': np.float64(0.5238345532119901), 'LSA': np.float64(0.5151676576329302), 'NMF': np.float64(0.5182506214086058)}\n",
      "Best Model: LDA\n"
     ]
    }
   ],
   "source": [
    "if not unprocessed.empty:\n",
    "    tokens = unprocessed['token_list'].tolist()\n",
    "    tfidf_corpus, dictionary = NLPEngine.get_tfidf_corpus(tokens)\n",
    "    winner_name, best_model, all_scores = NLPEngine.compare_models(tfidf_corpus, dictionary, tokens)\n",
    "\n",
    "    print(f\"Accuracy Scores: {all_scores}\")\n",
    "    print(f\"Winner: {winner_name}\")\n",
    "\n",
    "    # Tag comments with Topic ID and Confidence\n",
    "    topics_data = []\n",
    "    for bow in tfidf_corpus:\n",
    "        p = sorted(best_model[bow], key=lambda x: x[1], reverse=True)\n",
    "        topics_data.append((f\"{winner_name}_Topic_{p[0][0]}\", float(p[0][1])))\n",
    "\n",
    "    unprocessed['dominant_topic'], unprocessed['topic_confidence'] = zip(*topics_data)\n",
    "    \n",
    "    # Extract Vector Weights\n",
    "    taxonomy_vectors = NLPEngine.extract_taxonomy(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0dd86",
   "metadata": {},
   "source": [
    "Extract vectorized topic and tag comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f11ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VECTORIZED TOPIC TAXONOMY (Word Weights) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Word</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>way</td>\n",
       "      <td>0.066957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>level</td>\n",
       "      <td>0.063868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>teaching</td>\n",
       "      <td>0.063566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>next</td>\n",
       "      <td>0.063544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>supposed</td>\n",
       "      <td>0.059817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>silly</td>\n",
       "      <td>0.059663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>write</td>\n",
       "      <td>0.059598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>ampersandinvertedquestionmarkcaretsevenfivetri...</td>\n",
       "      <td>0.059386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>love</td>\n",
       "      <td>0.059230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Topic_0</td>\n",
       "      <td>teach</td>\n",
       "      <td>0.058566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Topic_1</td>\n",
       "      <td>password</td>\n",
       "      <td>0.067697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Topic_1</td>\n",
       "      <td>dish</td>\n",
       "      <td>0.066323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Topic_1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Topic_1</td>\n",
       "      <td>washed</td>\n",
       "      <td>0.065499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Topic_1</td>\n",
       "      <td>given</td>\n",
       "      <td>0.065433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic                                               Word    Weight\n",
       "0   Topic_0                                                way  0.066957\n",
       "1   Topic_0                                              level  0.063868\n",
       "2   Topic_0                                           teaching  0.063566\n",
       "3   Topic_0                                               next  0.063544\n",
       "4   Topic_0                                           supposed  0.059817\n",
       "5   Topic_0                                              silly  0.059663\n",
       "6   Topic_0                                              write  0.059598\n",
       "7   Topic_0  ampersandinvertedquestionmarkcaretsevenfivetri...  0.059386\n",
       "8   Topic_0                                               love  0.059230\n",
       "9   Topic_0                                              teach  0.058566\n",
       "10  Topic_1                                           password  0.067697\n",
       "11  Topic_1                                               dish  0.066323\n",
       "12  Topic_1                                            correct  0.065997\n",
       "13  Topic_1                                             washed  0.065499\n",
       "14  Topic_1                                              given  0.065433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Tag each comment with its dominant topic from the winner\n",
    "topics_data = []\n",
    "for bow in tfidf_corpus:\n",
    "    p = sorted(best_model[bow], key=lambda x: x[1], reverse=True)\n",
    "    topics_data.append((f\"Topic_{p[0][0]}\", float(p[0][1])))\n",
    "\n",
    "unprocessed['dominant_topic'], unprocessed['topic_confidence'] = zip(*topics_data)\n",
    "\n",
    "# 2. Extract the Vectorized Taxonomy (Word Weights)\n",
    "taxonomy_vectors = NLPEngine.extract_taxonomy(best_model)\n",
    "\n",
    "# --- VERIFICATION STEP: SHOW THE VECTORS ---\n",
    "print(\"\\n--- VECTORIZED TOPIC TAXONOMY (Word Weights) ---\")\n",
    "tax_df = pd.DataFrame(taxonomy_vectors, columns=['Topic', 'Word', 'Weight'])\n",
    "display(tax_df.head(15)) # This shows you the vectors in the notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d14f58",
   "metadata": {},
   "source": [
    "DB fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033eb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Database updated with Cleaned Text and Topic Vectors.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def persist_results(df, taxonomy):\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=\"127.0.0.1\", database=\"data_pipeline\", user=\"admin\", password=\"admin\")\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # 1. Update Comments Table (Includes sentiment and cleaned_text)\n",
    "        # Order: cleaned_text, dominant_topic, topic_confidence, sentiment, id\n",
    "        comment_data = list(df[['cleaned_text', 'dominant_topic', 'topic_confidence', 'sentiment', 'id']].itertuples(index=False, name=None))\n",
    "        \n",
    "        update_sql = \"\"\"\n",
    "            UPDATE airflow.processed_comments \n",
    "            SET cleaned_text = val.t, \n",
    "                dominant_topic = val.tp, \n",
    "                topic_confidence = val.c,\n",
    "                sentiment = val.s,\n",
    "                updated_at = CURRENT_TIMESTAMP\n",
    "            FROM (VALUES %s) AS val(t, tp, c, s, id)\n",
    "            WHERE comment_id = val.id;\n",
    "        \"\"\"\n",
    "        execute_values(cur, update_sql, comment_data)\n",
    "\n",
    "        # 2. Update Taxonomy (Word Weights)\n",
    "        cur.execute(\"CREATE TABLE IF NOT EXISTS airflow.topic_taxonomy (topic_id TEXT, word TEXT, weight FLOAT)\")\n",
    "        cur.execute(\"DELETE FROM airflow.topic_taxonomy\")\n",
    "        execute_values(cur, \"INSERT INTO airflow.topic_taxonomy (topic_id, word, weight) VALUES %s\", taxonomy)\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"[SUCCESS] DB updated with English Sentiment and Topic Taxonomy.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[X] DB Error: {e}\")\n",
    "    finally:\n",
    "        if conn: conn.close()\n",
    "\n",
    "if not unprocessed.empty:\n",
    "    persist_results(unprocessed, taxonomy_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd8c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
